{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import expm\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from qnl_projects.BHDecoder import qutrit_utils as qutils\n",
    "from qnl_analysis import SimTools as ST\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting between a CSUM and the Diagonal Unitaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two different diagonal unitaries which can be mapped to a CSUM with local unitaries.  Either we can:\n",
    "\n",
    "* put $2\\pi/3$ on the states $|11\\rangle$ and $|22\\rangle$, and $4\\pi/3$ on the states $|12\\rangle$ and $|21\\rangle$, or\n",
    "* put $4\\pi/3$ on the states $|11\\rangle$ and $|22\\rangle$, and $2\\pi/3$ on the states $|12\\rangle$ and $|21\\rangle$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_phases_1 = np.array([0,0,0,0,4,2,0,2,4])*np.pi/3\n",
    "desired_phases_2 = np.array([0,0,0,0,2,4,0,4,2])*np.pi/3\n",
    "\n",
    "U_ZZ_1 = np.diag(np.exp(1j*desired_phases_1))\n",
    "U_ZZ_2 = np.diag(np.exp(1j*desired_phases_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1 = np.kron(np.eye(3), qutils.qutrit_mapping['Hadamard'])\n",
    "H1dag = np.kron(np.eye(3), qutils.qutrit_mapping['HadamardDag'])\n",
    "\n",
    "H0 = np.kron(qutils.qutrit_mapping['Hadamard'], np.eye(3))\n",
    "H0dag = np.kron(qutils.qutrit_mapping['HadamardDag'], np.eye(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$U_{ZZ}^1$ can be converted into a CSUM by sandwitching it with a Hadamard on the target qubit.  That is, the sequence ($H_1^\\dagger$, $U_{ZZ}^1$, $H_1$) does a CSUM where Q0 is the control qubit and Q1 is the target qubit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.abs(reduce(np.dot, [H1,U_ZZ_1, H1dag])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, if we want to do a CSUM in the direction where Q0 is the target qubit and Q1 is the control qubit, then we should just apply the sequence ($H_0^\\dagger$, $U_{ZZ}^1$, $H_0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.abs(reduce(np.dot, [H0, U_ZZ_1, H0dag])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do a CMIN.  The sequence ($H_1$, $U_{ZZ}^1$, $H_1^\\dagger$) does a CMIN where Q0 is the control qubit and Q1 is the target qubit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.abs(reduce(np.dot, [H1dag,U_ZZ_1, H1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And similarly, to do a CMIN in the reverse direction, we just do ($H_0$, $U_{ZZ}^1$, $H_0^\\dagger$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.abs(reduce(np.dot, [H0dag,U_ZZ_1, H0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do similar things using the other diagonal unitary, which we called $U_{ZZ}^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.abs(reduce(np.dot, [H1,U_ZZ_2, H1dag])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.abs(reduce(np.dot, [H0,U_ZZ_2, H0dag])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.abs(reduce(np.dot, [H1dag,U_ZZ_2, H1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.abs(reduce(np.dot, [H0dag,U_ZZ_2, H0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining alphas and the ZZ Hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q0Q1alphas = {'11': -0.27935 * 2*np.pi , \n",
    "              '12': 0.1599 * 2*np.pi,\n",
    "              '21': -0.52793 * 2*np.pi,\n",
    "              '22': -0.742967 * 2*np.pi}\n",
    "\n",
    "Q6Q7_ZZdict = {'Q6GE_Q7inE': -0.2777, 'Q6GE_Q7inF': -0.6247, 'Q6EF_Q7inE': 0.5164, 'Q6EF_Q7inF': -0.114, \n",
    "        'Q7GE_Q6inE': -0.2743, 'Q7GE_Q6inF': 0.249, 'Q7EF_Q6inE': -0.3586, 'Q7EF_Q6inF': -0.9935} # measured values\n",
    "\n",
    "Q6Q7alphas = qutils.get_ZZ_parameters(qutrit_0 = 6, qutrit_1 = 7, measured_ZZ_dictionary = Q6Q7_ZZdict)[0]\n",
    "for key, val in Q6Q7alphas.items():\n",
    "    Q6Q7alphas[key] = val*2*np.pi\n",
    "\n",
    "def U_zz(evolution_time, alphas):\n",
    "    H_zz = np.diag([0,0,0,0,alphas['11'], alphas['12'], 0, alphas['21'], alphas['22']])\n",
    "    return expm(1j*H_zz*evolution_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 0 - Only using EF pi pulses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q0Q1_v0_times = {'T1': 0.61435267, 'T2': 0.10489224, 'T3': 0.61435267, 'T4': 0.10489224}\n",
    "Q6Q7_v0_times = {'T1': 0.09199338, 'T2': 0.61632224, 'T3': 0.09199338, 'T4': 0.61632224}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the single-qutrit operations we need\n",
    "Pi_EF = qutils.qutrit_mapping['EFX180']\n",
    "Pi_EFm = np.conj(Pi_EF)\n",
    "\n",
    "Pi_EF_0 = np.kron(Pi_EF, np.eye(3))\n",
    "Pi_EFm_0 = np.kron(Pi_EFm, np.eye(3))\n",
    "\n",
    "Pi_EF_1 = np.kron(np.eye(3), Pi_EF)\n",
    "Pi_EFm_1 = np.kron(np.eye(3), Pi_EFm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Uphi01_v0_4224= reduce(np.dot, [Pi_EF_1, U_zz(Q0Q1_v0_times['T4'], Q0Q1alphas), \n",
    "                       Pi_EF_0, U_zz(Q0Q1_v0_times['T3'], Q0Q1alphas), \n",
    "                       Pi_EFm_1, U_zz(Q0Q1_v0_times['T2'], Q0Q1alphas), \n",
    "                       Pi_EFm_0, U_zz(Q0Q1_v0_times['T1'], Q0Q1alphas)])\n",
    "\n",
    "\n",
    "Uphi01_v0_2442 = reduce(np.dot, [Pi_EF_1, U_zz(Q0Q1_v0_times['T3'], Q0Q1alphas), \n",
    "                       Pi_EF_0, U_zz(Q0Q1_v0_times['T4'], Q0Q1alphas), \n",
    "                       Pi_EFm_1, U_zz(Q0Q1_v0_times['T1'], Q0Q1alphas), \n",
    "                       Pi_EFm_0, U_zz(Q0Q1_v0_times['T2'], Q0Q1alphas)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.         -2.09439508  2.09439512\n",
      "  0.          2.09439512 -2.09439508]\n",
      "[ 0.          0.          0.          0.          2.09439512 -2.09439508\n",
      "  0.         -2.09439508  2.09439512]\n"
     ]
    }
   ],
   "source": [
    "Uphi67_v0_4224= reduce(np.dot, [Pi_EF_1, U_zz(Q6Q7_v0_times['T4'], Q6Q7alphas), \n",
    "                       Pi_EF_0, U_zz(Q6Q7_v0_times['T3'], Q6Q7alphas), \n",
    "                       Pi_EFm_1, U_zz(Q6Q7_v0_times['T2'], Q6Q7alphas), \n",
    "                       Pi_EFm_0, U_zz(Q6Q7_v0_times['T1'], Q6Q7alphas)])\n",
    "\n",
    "Uphi67_v0_2442 = reduce(np.dot, [Pi_EF_1, U_zz(Q6Q7_v0_times['T3'], Q6Q7alphas), \n",
    "                       Pi_EF_0, U_zz(Q6Q7_v0_times['T4'], Q6Q7alphas), \n",
    "                       Pi_EFm_1, U_zz(Q6Q7_v0_times['T1'], Q6Q7alphas), \n",
    "                       Pi_EFm_0, U_zz(Q6Q7_v0_times['T2'], Q6Q7alphas)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1 - Dynamically-decoupled from neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q0Q1_Delta_t = 0.59644 # us\n",
    "\n",
    "\n",
    "#define the single-qutrit operations we need \n",
    "X = np.array([[0,1,0],\n",
    "             [0,0,1],\n",
    "             [1,0,0]])\n",
    "\n",
    "Pi_GE = qutils.qutrit_mapping['X180']\n",
    "EFZm90 = qutils.resulting_unitary([['EFZ-90']])\n",
    "\n",
    "Pi_GE_nophi = np.dot(Pi_GE, EFZm90)*(1j)\n",
    "\n",
    "XX = np.kron(X,X)\n",
    "\n",
    "GEGE = np.kron(Pi_GE_nophi, Pi_GE_nophi)\n",
    "\n",
    "#define the local Z gates which correct the phase on our state\n",
    "Z1 = expm(-1j * 2*np.pi/3 * np.diag([0,1,1]))\n",
    "Z2 = expm(-1j * 2*np.pi/3 * np.diag([0,1,1]))\n",
    "\n",
    "total_Z = np.kron(Z1, Z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_phi_dd = np.exp(1j*2.55411798)*reduce(np.dot, reversed([U_ZZ, XX, U_ZZ, XX, U_ZZ, GEGE, U_ZZ, XX, U_ZZ, XX, U_ZZ, GEGE, total_Z]))\n",
    "U_CSUM_dd = reduce(np.dot, reversed([H1, U_phi_dd, H1dag]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

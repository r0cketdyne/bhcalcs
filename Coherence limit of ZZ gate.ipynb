{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy as sc\n",
    "import inspect\n",
    "import copy\n",
    "from scipy.linalg import expm\n",
    "from functools import reduce\n",
    "import itertools\n",
    "import seaborn\n",
    "from numpy import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/qnl')\n",
    "\n",
    "import time\n",
    "\n",
    "from importlib import reload\n",
    "from qnl_analysis import SimTools as ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('qutrit_decay.yaml', 'r') as f:\n",
    "    decay_parms = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q0': {'T1_EF': 26, 'T1_GE': 40, 'Tphi_EF': 45, 'Tphi_GE': 50},\n",
       " 'Q1': {'T1_EF': 60, 'T1_GE': 50, 'Tphi_EF': 35, 'Tphi_GE': 33},\n",
       " 'Q2': {'T1_EF': 26, 'T1_GE': 40, 'Tphi_EF': 45, 'Tphi_GE': 50},\n",
       " 'Q3': {'T1_EF': 60, 'T1_GE': 50, 'Tphi_EF': 35, 'Tphi_GE': 33},\n",
       " 'Q4': {'T1_EF': 26, 'T1_GE': 40, 'Tphi_EF': 45, 'Tphi_GE': 50}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decay_parms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZZ-CSUM with the original (4 EF pi pulses) method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the entangling ZZ Hamiltonian between our qutrits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_11 = 2 * np.pi * -0.27935*1e6 # Hz\n",
    "alpha_12 = 2 * np.pi * 0.1599*1e6 # Hz\n",
    "alpha_21 = 2 * np.pi * -0.52793*1e6 # Hz\n",
    "alpha_22 = 2 * np.pi * -0.742967*1e6 # Hz\n",
    "\n",
    "H_ZZ = qt.Qobj(np.diag([0,0,0,0,alpha_11, alpha_12, 0, alpha_21, alpha_22]), dims = [[3,3],[3,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next calculate the required times for these to be turned into a CSUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = 0.614 * 1e-6 #s\n",
    "T2 = 0.105 * 1e-6 #s\n",
    "T3 = 0.614 * 1e-6 #s\n",
    "T4 = 0.105 * 1e-6 #s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CSUM gate uses some single-qutrit unitaries, which we define below. In particular, we use the Hadamard gate and $\\pi$-pulses on the $|E\\rangle\\leftrightarrow |F\\rangle$ subspace of each qutrit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = np.exp(2*np.pi*1j/3)\n",
    "omega_inv = np.exp(-2*np.pi*1j/3)\n",
    "Hadamard = qt.Qobj(1/np.sqrt(3)*np.array([[1,1,1],\n",
    "                                         [1, omega, omega_inv],\n",
    "                                         [1, omega_inv, omega]]))\n",
    "PiEF = qt.Qobj(np.array([[1,0,0],\n",
    "                        [0,0,-1j],\n",
    "                        [0,-1j,0]]))\n",
    "\n",
    "PiEFm = qt.Qobj(np.array([[1,0,0],\n",
    "                        [0,0,1j],\n",
    "                        [0,1j,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hadamard_Q1 = qt.tensor(Id, Hadamard)\n",
    "Hadamard_Q1_dag = Hadamard_Q1.dag()\n",
    "\n",
    "PiEF_Q0 = qt.tensor(PiEF, Id)\n",
    "PiEF_Q0_dag = PiEF_Q0.dag()\n",
    "\n",
    "PiEFm_Q0 = qt.tensor(PiEFm, Id)\n",
    "PiEFm_Q0_dag = PiEFm_Q0.dag()\n",
    "\n",
    "PiEF_Q1 = qt.tensor(Id, PiEF)\n",
    "PiEF_Q1_dag = PiEF_Q1.dag()\n",
    "\n",
    "PiEFm_Q1 = qt.tensor(Id,PiEFm)\n",
    "PiEFm_Q1_dag = PiEFm_Q1.dag()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity_of_csum():\n",
    "    \n",
    "    gamma1GE_0 = 1./(40e-6) # 1/s\n",
    "    gamma1EF_0 = 1./(26e-6) # 1/s\n",
    "\n",
    "    C0 = np.sqrt(gamma1GE_0)*qt.tensor(qt.Qobj(np.array([[0,1,0],[0,0,0],[0,0,0]])), Id)\n",
    "    C1 = np.sqrt(gamma1EF_0)*qt.tensor(qt.Qobj(np.array([[0,0,0],[0,0,1],[0,0,0]])), Id)\n",
    "\n",
    "    gammaphiGE_0 = 1/(50e-6) # 1/s\n",
    "    gammaphiEF_0 = 1/(45e-6) # 1/s\n",
    "\n",
    "    D0 = np.sqrt(gammaphiGE_0) * qt.tensor(qt.Qobj(np.diag([1,-1,-1])), Id)\n",
    "    D1 = np.sqrt(gammaphiEF_0) * qt.tensor(qt.Qobj(np.diag([-1,1,-1])), Id)\n",
    "\n",
    "    gamma1GE_1 = 1./(50e-6) # 1/s\n",
    "    gamma1EF_1 = 1./(33e-6) # 1/s\n",
    "\n",
    "    E0 = np.sqrt(gamma1GE_1)*qt.tensor(Id, qt.Qobj(np.array([[0,1,0],[0,0,0],[0,0,0]])))\n",
    "    E1 = np.sqrt(gamma1EF_1)*qt.tensor(Id, qt.Qobj(np.array([[0,0,0],[0,0,1],[0,0,0]])))\n",
    "\n",
    "    gammaphiGE_1 = 1/(60e-6) # 1/s\n",
    "    gammaphiEF_1 = 1/(35e-6) # 1/s\n",
    "\n",
    "    F0 = np.sqrt(gammaphiGE_1) * qt.tensor(Id, qt.Qobj(np.diag([1,-1,-1])))\n",
    "    F1 = np.sqrt(gammaphiEF_1) * qt.tensor(Id, qt.Qobj(np.diag([-1,1,-1])))\n",
    "    \n",
    "    fidelities = []\n",
    "    \n",
    "    for state_0 in range(3):\n",
    "        for state_1 in range(3):\n",
    "            state = [state_0, state_1]\n",
    "            \n",
    "            psi0 = qt.tensor(qt.basis(3,state[0])*qt.basis(3,state[0]).dag(),qt.basis(3,state[1])*qt.basis(3,state[1]).dag())\n",
    "\n",
    "            # now do the CSUM\n",
    "            psi0 = Hadamard_Q1_dag*psi0*Hadamard_Q1\n",
    "\n",
    "            result = qt.mesolve(H_ZZ, psi0, np.linspace(0,T1,100), [C0, C1, D0, D1, E0, E1, F0, F1], [])\n",
    "            psi0 = result.states[-1]\n",
    "\n",
    "            psi0 = PiEF_Q0*psi0*PiEF_Q0_dag\n",
    "\n",
    "            result = qt.mesolve(H_ZZ, psi0, np.linspace(0,T2,100), [C0, C1, D0, D1, E0, E1, F0, F1], [])\n",
    "            psi0 = result.states[-1]\n",
    "\n",
    "            psi0 = PiEF_Q1*psi0*PiEF_Q1_dag\n",
    "\n",
    "            result = qt.mesolve(H_ZZ, psi0, np.linspace(0,T3,100), [C0, C1, D0, D1, E0, E1, F0, F1], [])\n",
    "\n",
    "            psi0 = result.states[-1]\n",
    "            psi0 = PiEFm_Q0*psi0*PiEFm_Q0_dag\n",
    "\n",
    "            result = qt.mesolve(H_ZZ, psi0, np.linspace(0,T4,100), [C0, C1, D0, D1, E0, E1, F0, F1], [])\n",
    "\n",
    "            psi0 = result.states[-1]\n",
    "            psi0 = PiEFm_Q1*psi0*PiEFm_Q1_dag\n",
    "\n",
    "            psi0 = Hadamard_Q1*psi0*Hadamard_Q1_dag\n",
    "\n",
    "            fidelities.append(np.abs(psi0[3* state_0 + ((state_0 + state_1)%3), 3* state_0 + ((state_0 + state_1)%3)]))\n",
    "    \n",
    "    return fidelities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fidelity_of_csum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e7b376140e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfidelity_of_csum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fidelity_of_csum' is not defined"
     ]
    }
   ],
   "source": [
    "fidelity_of_csum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9025060315655272"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(fidelity_of_csum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZZ-CSUM with the shortest time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the entangling ZZ Hamiltonian between our qutrits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_11 = 2 * np.pi * -0.27935 * 1e6 # Hz\n",
    "alpha_12 = 2 * np.pi * 0.1599 * 1e6 # Hz\n",
    "alpha_21 = 2 * np.pi * -0.52793 * 1e6 # Hz\n",
    "alpha_22 = 2 * np.pi * -0.742967 * 1e6 # Hz\n",
    "\n",
    "H_ZZ = qt.Qobj(np.diag([0,0,0,0,alpha_11, alpha_12, 0, alpha_21, alpha_22]), dims = [[3,3],[3,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next calculate the required times for these to be turned into a CSUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = 0.3986566 * 1e-6 #s\n",
    "T2 = 0.3986566 * 1e-6  #s\n",
    "T3 = 0.13608932 * 1e-6 #s\n",
    "T4 = 0.13608932 * 1e-6 #s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CSUM gate uses some single-qutrit unitaries, which we define below. In particular, we use the Hadamard gate and $\\pi$-pulses on the $|E\\rangle\\leftrightarrow |F\\rangle$ subspace of each qutrit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = np.exp(2*np.pi*1j/3)\n",
    "omega_inv = np.exp(-2*np.pi*1j/3)\n",
    "Hadamard = 1/np.sqrt(3)*np.array([[1,1,1],\n",
    "                                         [1, omega, omega_inv],\n",
    "                                         [1, omega_inv, omega]])\n",
    "PiEF = np.array([[1,0,0],\n",
    "                [0,0,-1j],\n",
    "                [0,-1j,0]])\n",
    "\n",
    "PiEFm = np.array([[1,0,0],\n",
    "                [0,0,1j],\n",
    "                [0,1j,0]])\n",
    "\n",
    "PiGE = np.array([[0,-1j,0],\n",
    "                [-1j,0,0],\n",
    "                [0,0,1]])\n",
    "\n",
    "PiGEm = np.array([[0,1j,0],\n",
    "                [1j,0,0],\n",
    "                [0,0,1]])\n",
    "\n",
    "Id = np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PiEF_Q0 = np.kron(PiEF, Id)\n",
    "\n",
    "PiEFm_Q0 = np.kron(PiEFm, Id)\n",
    "\n",
    "PiEF_Q1 = np.kron(Id, PiEF)\n",
    "\n",
    "PiEFm_Q1 = np.kron(Id,PiEFm)\n",
    "\n",
    "PiGE_Q0 = np.kron(PiGE, Id)\n",
    "\n",
    "PiGEm_Q0 = np.kron(PiGEm, Id)\n",
    "\n",
    "PiGE_Q1 = np.kron(Id, PiGE)\n",
    "\n",
    "PiGEm_Q1 = np.kron(Id,PiGEm)\n",
    "\n",
    "H_ZZ = np.diag([0,0,0,0,alpha_11, alpha_12, 0, alpha_21, alpha_22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## single-qutrit permutation matrices\n",
    "P = {'P0': np.array([[1,0,0],\n",
    "                     [0,1,0],\n",
    "                     [0,0,1]]),\n",
    "     'P1': np.array([[1,0,0],\n",
    "                     [0,0,1],\n",
    "                     [0,1,0]]),\n",
    "     'P2': np.array([[0,1,0],\n",
    "                     [1,0,0],\n",
    "                     [0,0,1]]),\n",
    "     'P3': np.array([[0,1,0],\n",
    "                     [0,0,1],\n",
    "                     [1,0,0]]),\n",
    "     'P4': np.array([[0,0,1],\n",
    "                     [1,0,0],\n",
    "                     [0,1,0]]),\n",
    "     'P5': np.array([[0,0,1],\n",
    "                     [0,1,0],\n",
    "                     [1,0,0]]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(P['P0'].T,P['P3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.+0.j,  0.+0.j,  0.+0.j],\n",
       "       [ 0.+0.j, -1.+0.j,  0.+0.j],\n",
       "       [ 0.+0.j,  0.+0.j,  1.+0.j]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(np.dot, reversed([PiGE, PiEF, PiGE, PiEF, PiEF, PiGE, PiEF, PiGE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PiEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSUM_permutation_1 = np.dot(np.kron(P['P1'].T,P['P4'].T), np.kron(P['P0'], P['P0']))\n",
    "CSUM_permutation_2 = np.dot(np.kron(P['P4'].T,P['P5'].T), np.kron(P['P1'], P['P4']))\n",
    "CSUM_permutation_3 = np.dot(np.kron(P['P5'].T,P['P3'].T), np.kron(P['P4'], P['P5']))\n",
    "CSUM_permutation_4 = np.dot(np.kron(P['P3'].T,P['P2'].T), np.kron(P['P5'], P['P3']))\n",
    "CSUM_permutation_5 = np.dot(np.kron(P['P0'].T,P['P0'].T), np.kron(P['P3'], P['P2']))\n",
    "\n",
    "Phi_00 = -1*(alpha_22 * T2 + alpha_11 * T3 + alpha_21 * T4)\n",
    "Phi_01 = -1*(alpha_21 * T2 + alpha_22 * T3)\n",
    "Phi_02 = -1*(alpha_12 * T4)\n",
    "Phi_10 = -1*(alpha_22 * T1 + alpha_11 * T3 + alpha_21 * T4)\n",
    "Phi_20 = -1*(alpha_12 * T1 + alpha_12 * T2)\n",
    "\n",
    "Z_corr = np.kron(expm(-1j*np.diag([0,Phi_10 - Phi_00, Phi_20 - Phi_00])),\n",
    "                   expm(-1j*np.diag([0,Phi_01 - Phi_00, Phi_02 - Phi_00])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hadamard_Q1 = np.kron(Id, Hadamard)\n",
    "Hadamard_Q1_dag = np.conj(Hadamard_Q1.T)\n",
    "\n",
    "Hadamard_Q0 = np.kron(Hadamard, Id)\n",
    "Hadamard_Q0_dag = np.conj(Hadamard_Q0.T)\n",
    "\n",
    "Hadamard_Q0_map = unitary_op_to_map(Hadamard_Q0)\n",
    "Hadamard_Q0_dag_map = unitary_op_to_map(Hadamard_Q0_dag)\n",
    "\n",
    "Hadamard_Q1_map = unitary_op_to_map(Hadamard_Q1)\n",
    "Hadamard_Q1_dag_map = unitary_op_to_map(Hadamard_Q1_dag)\n",
    "\n",
    "Z_corr_map = unitary_op_to_map(Z_corr)\n",
    "\n",
    "Perm1_map = unitary_op_to_map(CSUM_permutation_1)\n",
    "Perm2_map = unitary_op_to_map(CSUM_permutation_2)\n",
    "Perm3_map = unitary_op_to_map(CSUM_permutation_3)\n",
    "Perm4_map = unitary_op_to_map(CSUM_permutation_4)\n",
    "Perm5_map = unitary_op_to_map(CSUM_permutation_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idling_Lindbladian' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-882438718ca2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midling_map_T1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midling_Lindbladian\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mT1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0midling_map_T2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midling_Lindbladian\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mT2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0midling_map_T3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midling_Lindbladian\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mT3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0midling_map_T4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midling_Lindbladian\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mT4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'idling_Lindbladian' is not defined"
     ]
    }
   ],
   "source": [
    "idling_map_T1 = sc.linalg.expm(idling_Lindbladian*T1)\n",
    "idling_map_T2 = sc.linalg.expm(idling_Lindbladian*T2)\n",
    "idling_map_T3 = sc.linalg.expm(idling_Lindbladian*T3)\n",
    "idling_map_T4 = sc.linalg.expm(idling_Lindbladian*T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_CSUMp1_map = reduce(np.dot, [Hadamard_Q1_map, Z_corr_map, Perm5_map, idling_map_T4, Perm4_map, idling_map_T3, Perm3_map, idling_map_T2, Perm2_map, idling_map_T1, Perm1_map, Hadamard_Q1_dag_map])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = (2,2)\n",
    "psi_init = [0,0,0,0,0,0,0,0,0]\n",
    "psi_init[3*init_state[0] + init_state[1]] = 1\n",
    "\n",
    "rho_init = ST.vec_to_dm(psi_init)\n",
    "rho_init_vec = rho_init.T.reshape(rho_init.shape[0]*rho_init.shape[1],-1)\n",
    "\n",
    "rho_final_vec = np.dot(real_CSUMp1_map, rho_init_vec)\n",
    "\n",
    "rho_final = rho_final_vec.reshape(9,9).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.001, 0.   , 0.001, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.001, 0.001, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.001, 0.001, 0.009, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.002, 0.003, 0.001, 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.003, 0.006, 0.002, 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.001, 0.002, 0.001, 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.026, 0.002, 0.007],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.002, 0.929, 0.002],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.007, 0.002, 0.026]])"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.abs(rho_final),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9268593749999999"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.975*0.975*0.975"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "00: 92.5\n",
    "01: 92.5\n",
    "02: 92.5\n",
    "10: 92.5\n",
    "11: 92.5\n",
    "12: 92.5\n",
    "20: 92.9\n",
    "21: 92.9\n",
    "22: 92.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_csum(state_0 = 0, state_1 = 0):\n",
    "    \n",
    "    fidelities = []\n",
    "    \n",
    "    psi0 = np.array([0,0,0,0,0,0,0,0,0])\n",
    "    psi0[state_0*3 + state_1] = 1\n",
    "    \n",
    "    psi0 = np.dot(np.kron(np.eye(3), np.conj(Hadamard.T)), psi0)\n",
    "    \n",
    "    # do the first permutation\n",
    "    psi0 = reduce(np.dot, [CSUM_permutation_1,  psi0]) \n",
    "\n",
    "    psi0 = np.dot(expm(-1j*H_ZZ*T1),psi0)\n",
    "\n",
    "    psi0 = reduce(np.dot, [CSUM_permutation_2, psi0])\n",
    "\n",
    "    psi0 = np.dot(expm(-1j*H_ZZ*T2),psi0)\n",
    "\n",
    "    psi0 = reduce(np.dot, [CSUM_permutation_3, psi0])\n",
    " \n",
    "    psi0 = np.dot(expm(-1j*H_ZZ*T3),psi0)            \n",
    "\n",
    "    psi0 = reduce(np.dot, [CSUM_permutation_4, psi0])\n",
    "\n",
    "    psi0 = np.dot(expm(-1j*H_ZZ*T4),psi0)\n",
    "            \n",
    "    psi0 = reduce(np.dot, [CSUM_permutation_5, psi0])\n",
    "   \n",
    "    Phi_00 = -1*(alpha_22 * T2 + alpha_11 * T3 + alpha_21 * T4)\n",
    "    Phi_01 = -1*(alpha_21 * T2 + alpha_22 * T3)\n",
    "    Phi_02 = -1*(alpha_12 * T4)\n",
    "    Phi_10 = -1*(alpha_22 * T1 + alpha_11 * T3 + alpha_21 * T4)\n",
    "    Phi_20 = -1*(alpha_12 * T1 + alpha_12 * T2)\n",
    "\n",
    "    Z_corr = np.kron(expm(-1j*np.diag([0,Phi_10 - Phi_00, Phi_20 - Phi_00])),\n",
    "                       expm(-1j*np.diag([0,Phi_01 - Phi_00, Phi_02 - Phi_00])))\n",
    "    \n",
    "    psi0 = reduce(np.dot, [Z_corr, psi0])\n",
    "    psi0 = psi0*exp(-1j*Phi_00)\n",
    "    \n",
    "    psi0 = np.dot(np.kron(np.eye(3), Hadamard), psi0)\n",
    "    \n",
    "    print(np.abs(psi0))\n",
    "\n",
    "    return psi0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        +0.j        ,  0.        +0.j        ,\n",
       "         0.        +0.j        ],\n",
       "       [ 0.        +0.j        ,  0.82891884+0.55936889j,\n",
       "         0.        +0.j        ],\n",
       "       [-0.        +0.j        , -0.        +0.j        ,\n",
       "        -0.89888709+0.43818032j]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expm(-1j*np.diag([0,Phi_01 - Phi_00, Phi_02 - Phi_00]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120.00000044742617"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.angle(-0.89888709+0.43818032j)*180/np.pi - np.angle(0.82891884+0.55936889j)*180/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+00 2.49800181e-16 1.94289029e-16 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "test_csum(0,0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct calculation of the two-qutrit quantum map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate the performance of the ZZ-based CSUM gate in the scrambling algorithm, we extract here the quantum map by directly (numerically) exponentiating the Lindbladian.  We'll compare this with the results obtained by solving the master equation above.  This calculation does not rely on QuTiP and thus serves as an independent check of the dynamics.\n",
    "\n",
    "Following [this paper](https://arxiv.org/pdf/1510.08634.pdf), if we vectorize the density matrix by simply ordering the columns one below the other, so that the $(a,b)$ entry of $\\rho$ is the $(bn + a)$$^{th}$ entry (zero-indexed) of the vector $\\vec{r}$, and if we write the master equation in standard form as \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac { d } { d t } \\hat { \\boldsymbol { \\rho } } ( t ) = \\mathcal { L } \\hat { \\boldsymbol { \\rho } } = -  i   [ \\hat { \\mathbf { H } } , \\hat { \\boldsymbol { \\rho } } ] + \\sum _ { i } \\gamma _ { i } \\left( \\hat { \\mathbf { A } } _ { i } \\hat { \\boldsymbol { \\rho } } \\hat { \\mathbf { A } } _ { i } ^ { \\dagger } - \\frac { 1 } { 2 } \\left\\{ \\hat { \\mathbf { A } } _ { i } ^ { \\dagger } \\hat { \\mathbf { A } } _ { i } , \\hat { \\boldsymbol { \\rho } } \\right\\} \\right)\n",
    "\\end{equation},\n",
    "\n",
    "then the vectorized versions of the operators are:\n",
    "\n",
    "\\begin{equation}\n",
    "[ \\hat { \\mathbf { H } } , \\hat { \\boldsymbol { \\rho } } ] \\rightarrow  \\left( I \\otimes \\hat { \\mathbf { H } } - \\hat { \\mathbf { H } } ^ { T } \\otimes I \\right) \\vec { r }\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat { \\mathbf { A } } _ { i } \\hat { \\boldsymbol { \\rho } } \\hat { \\mathbf { A } } _ { i } ^ { \\dagger } \\rightarrow \\left( \\left( \\hat { \\mathbf { A } } _ { i } ^ { \\dagger } \\right) ^ { T } \\otimes \\hat { \\mathbf { A } } _ { i } \\right) \\vec { r }\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat { \\mathbf { A } } _ { i } ^ { \\dagger } \\mathbf { \\hat { A } } _ { i } \\hat { \\boldsymbol { \\rho } } \\rightarrow \\left( I \\otimes \\hat { \\mathbf { A } } _ { i } ^ { \\dagger } \\hat { \\mathbf { A } } _ { i } \\right) \\vec { r }\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat { \\boldsymbol { \\rho } } \\hat { \\mathbf { A } } _ { i } ^ { \\dagger } \\hat { \\mathbf { A } } _ { i } \\rightarrow \\left( \\left( \\hat { \\mathbf { A } } _ { i } ^ { \\dagger } \\hat { \\mathbf { A } } _ { i } \\right) ^ { T } \\otimes I \\right) \\vec { r }\n",
    "\\end{equation}\n",
    "\n",
    "That means the whole Lindbladian can be expressed as:\n",
    "\n",
    "\\begin{equation}\n",
    "L = -i \\left( I \\otimes \\hat { \\mathbf { H } } - \\hat { \\mathbf { H } } ^ { T } \\otimes I \\right)+ \\sum _ { i } \\gamma _ { i } \\left( \\left( \\hat { \\mathbf { A } } _ { i } ^ { \\dagger } \\right) ^ { T } \\otimes \\hat { \\mathbf { A } } _ { i } - \\frac { 1 } { 2 } \\left( I \\otimes \\hat { \\mathbf { A } } _ { i } ^ { \\dagger } \\hat { \\mathbf { A } } _ { i } + \\left( \\hat { \\mathbf { A } } _ { i } ^ { \\dagger } \\hat { \\mathbf { A } } _ { i } \\right) ^ { T } \\otimes I \\right) \\right)\n",
    "\\end{equation}\n",
    "\n",
    "In terms of which the Master equation becomes:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac { d } { d t } \\vec { r } = L \\vec { r }\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Take a look at the code here for matrix_Lindbladian, a function which implements the above calculations given a Hamiltonian, collapse rates, and collapse operators:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_Lindbladian(Hamiltonian, collapse_rates, collapse_operators):\n",
    "    \"\"\"\n",
    "    Forms a Lindbladian superoperator in 'vectorized' form, \n",
    "    i.e. a matrix which acts on a 'vectorized' density matrix\n",
    "    \n",
    "    Arguments:\n",
    "    Hamiltonian - an n x n matrix (if the Hilbert space dimension is n) \n",
    "                    describing the coherent part of the system's evolution\n",
    "    collapse_rates - a list of numbers, each of which corresponds to a collapse_operator in \n",
    "                    the list collapse_operators.  \n",
    "    collapse_operators - a list of operators which act as collapse operators in the \n",
    "                    master equation describing the evolution\n",
    "                    \n",
    "    Returns:\n",
    "    Lindbladian - an n^2 x n^2 matrix representing the Lindbladian superoperator in vectorized form\n",
    "                The convention is that this acts on a density matrix which has been vectorized by \n",
    "                stacking columns one on top of the other. \n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(collapse_rates) == len(collapse_operators)\n",
    "    \n",
    "    system_dimension = Hamiltonian.shape\n",
    "    \n",
    "    identity_matrix = np.eye(system_dimension[0])\n",
    "    \n",
    "    # start by vectorizing the Hamiltonian part of the Lindbladian\n",
    "    Lindbladian = -1j * (np.kron(identity_matrix, Hamiltonian) - np.kron(Hamiltonian.T, identity_matrix) )\n",
    "    \n",
    "    # then add each collapse term, again in vectorized form\n",
    "    for collapse_index, collapse_rate in enumerate(collapse_rates):\n",
    "        collapse_operator = collapse_operators[collapse_index]\n",
    "        \n",
    "        collapse_term = collapse_rate * (np.kron(np.conj(collapse_operator), collapse_operator) - \\\n",
    "                                        0.5 * np.kron(identity_matrix, np.dot(np.conj(collapse_operator.T), collapse_operator)) - \\\n",
    "                                        0.5 * np.kron(np.dot(np.conj(collapse_operator.T), collapse_operator), identity_matrix))\n",
    "        \n",
    "        Lindbladian = Lindbladian + collapse_term\n",
    "    \n",
    "    return Lindbladian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = np.eye(3)\n",
    "\n",
    "H_ZZ = np.diag([0,0,0,0,alpha_11, alpha_12, 0, alpha_21, alpha_22])\n",
    "\n",
    "gamma1GE_0 = 1./(40e-6) # 1/s\n",
    "gamma1EF_0 = 1./(26e-6) # 1/s\n",
    "\n",
    "C0 = np.kron(np.array([[0,1,0],[0,0,0],[0,0,0]]), Id)\n",
    "C1 = np.kron(np.array([[0,0,0],[0,0,1],[0,0,0]]), Id)\n",
    "\n",
    "gammaphiGE_0 = 1/(50e-6) # 1/s\n",
    "gammaphiEF_0 = 1/(45e-6) # 1/s\n",
    "\n",
    "D0 = np.kron(np.diag([1,-1,-1]), Id)\n",
    "D1 = np.kron(np.diag([-1,1,-1]), Id)\n",
    "\n",
    "gamma1GE_1 = 1./(50e-6) # 1/s\n",
    "gamma1EF_1 = 1./(33e-6) # 1/s\n",
    "\n",
    "E0 = np.kron(Id, np.array([[0,1,0],[0,0,0],[0,0,0]]))\n",
    "E1 = np.kron(Id, np.array([[0,0,0],[0,0,1],[0,0,0]]))\n",
    "\n",
    "gammaphiGE_1 = 1/(60e-6) # 1/s\n",
    "gammaphiEF_1 = 1/(35e-6) # 1/s\n",
    "\n",
    "F0 = np.kron(Id, np.diag([1,-1,-1]))\n",
    "F1 = np.kron(Id, np.diag([-1,1,-1]))\n",
    "    \n",
    "qutrit_collapse_rates = [gamma1GE_0, gamma1EF_0, gammaphiGE_0, gammaphiEF_0, gamma1GE_1, gamma1EF_1, gammaphiGE_1, gammaphiEF_1]\n",
    "qutrit_collapse_ops = [C0, C1, D0, D1, E0, E1, F0, F1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "idling_Lindbladian = matrix_Lindbladian(H_ZZ, qutrit_collapse_rates, qutrit_collapse_ops)\n",
    "nodecay_Lindbladian = matrix_Lindbladian(H_ZZ, [0]*8, qutrit_collapse_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "idling_map_T1 = sc.linalg.expm(idling_Lindbladian*T1)\n",
    "idling_map_T2 = sc.linalg.expm(idling_Lindbladian*T2)\n",
    "idling_map_T3 = sc.linalg.expm(idling_Lindbladian*T3)\n",
    "idling_map_T4 = sc.linalg.expm(idling_Lindbladian*T4)\n",
    "\n",
    "idling_nodecay_map_T1 = sc.linalg.expm(nodecay_Lindbladian*T1)\n",
    "idling_nodecay_map_T2 = sc.linalg.expm(nodecay_Lindbladian*T2)\n",
    "idling_nodecay_map_T3 = sc.linalg.expm(nodecay_Lindbladian*T3)\n",
    "idling_nodecay_map_T4 = sc.linalg.expm(nodecay_Lindbladian*T4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the vectorized map representations of the unitary operations representing the $\\pi$ pulses and the Hadamard gate.  From the considerations above, namely the equation\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat { \\mathbf { A } } _ { i } \\hat { \\boldsymbol { \\rho } } \\hat { \\mathbf { A } } _ { i } ^ { \\dagger } \\rightarrow \\left( \\left( \\hat { \\mathbf { A } } _ { i } ^ { \\dagger } \\right) ^ { T } \\otimes \\hat { \\mathbf { A } } _ { i } \\right) \\vec { r }\n",
    "\\end{equation}\n",
    "\n",
    "we gather that a unitary operation $\\hat U$ is represented as $\\hat U^* \\otimes \\hat U$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This is implemented in ST.unitary_op_to_map(), using the code below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unitary_op_to_map(unitary_op):\n",
    "    \"\"\"\n",
    "    Given a unitary operator, converts it into vectorized form.\n",
    "\n",
    "    that is, the n x n matrix unitary_op is defined such that it transforms density matrices via\n",
    "    rho_out = unitary_op * rho_in * unitary_op.dagger\n",
    "    \n",
    "    The vectorized version is defined such that it acts on the vectorized density matrix rho_in_vec by\n",
    "    rho_out_vec = vectorized_unitary_op * rho_in_vec\n",
    "\n",
    "    The vectorized version of a unitary operator is given by np.kron(unitary_op*, unitary_op) \n",
    "    [see https://arxiv.org/pdf/1510.08634.pdf (page 4) for a proof]\n",
    "    \"\"\"\n",
    "    return np.kron(np.conj(unitary_op), unitary_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = np.exp(2*np.pi*1j/3)\n",
    "omega_inv = np.exp(-2*np.pi*1j/3)\n",
    "Hadamard = 1/np.sqrt(3)*np.array([[1,1,1],\n",
    "                                 [1, omega, omega_inv],\n",
    "                                 [1, omega_inv, omega]])\n",
    "PiEF = np.array([[1,0,0],\n",
    "                [0,0,-1j],\n",
    "                [0,-1j,0]])\n",
    "\n",
    "PiEFm = np.array([[1,0,0],\n",
    "                [0,0,1j],\n",
    "                [0,1j,0]])\n",
    "\n",
    "Hadamard_Q1 = np.kron(Id, Hadamard)\n",
    "Hadamard_Q1_dag = np.conj(Hadamard_Q1.T)\n",
    "\n",
    "Hadamard_Q0 = np.kron(Hadamard, Id)\n",
    "Hadamard_Q0_dag = np.conj(Hadamard_Q0.T)\n",
    "\n",
    "PiEF_Q0 = np.kron(PiEF, Id)\n",
    "PiEFm_Q0 = np.kron(PiEFm, Id)\n",
    "PiEF_Q1 = np.kron(Id, PiEF)\n",
    "PiEFm_Q1 = np.kron(Id,PiEFm)\n",
    "\n",
    "PiEF_Q0_map = ST.unitary_op_to_map(PiEF_Q0)\n",
    "PiEFm_Q0_map = ST.unitary_op_to_map(PiEFm_Q0)\n",
    "PiEF_Q1_map = ST.unitary_op_to_map(PiEF_Q1)\n",
    "PiEFm_Q1_map = ST.unitary_op_to_map(PiEFm_Q1)\n",
    "Hadamard_Q1_map = ST.unitary_op_to_map(Hadamard_Q1)\n",
    "Hadamard_Q1_dag_map = ST.unitary_op_to_map(Hadamard_Q1_dag)\n",
    "\n",
    "Hadamard_Q0_map = ST.unitary_op_to_map(Hadamard_Q0)\n",
    "Hadamard_Q0_dag_map = ST.unitary_op_to_map(Hadamard_Q0_dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_CSUMp1_map = reduce(np.dot, [Hadamard_Q1_map, PiEFm_Q1_map, idling_map_T4, PiEFm_Q0_map, idling_map_T3, PiEF_Q1_map, idling_map_T2, PiEF_Q0_map, idling_map_T1, Hadamard_Q1_dag_map])\n",
    "real_CMINp1_map = reduce(np.dot, [Hadamard_Q1_map, PiEFm_Q1_map, idling_map_T3, PiEFm_Q0_map, idling_map_T4, PiEF_Q1_map, idling_map_T1, PiEF_Q0_map, idling_map_T2, Hadamard_Q1_dag_map])\n",
    "\n",
    "ideal_CSUMp1_map = reduce(np.dot, [Hadamard_Q1_map, PiEFm_Q1_map, idling_nodecay_map_T4, PiEFm_Q0_map, idling_nodecay_map_T3, PiEF_Q1_map, idling_nodecay_map_T2, PiEF_Q0_map, idling_nodecay_map_T1, Hadamard_Q1_dag_map])\n",
    "ideal_CMINp1_map = reduce(np.dot, [Hadamard_Q1_map, PiEFm_Q1_map, idling_nodecay_map_T3, PiEFm_Q0_map, idling_nodecay_map_T4, PiEF_Q1_map, idling_nodecay_map_T1, PiEF_Q0_map, idling_nodecay_map_T2, Hadamard_Q1_dag_map])\n",
    "\n",
    "real_CSUMm1_map = reduce(np.dot, [Hadamard_Q0_map, PiEFm_Q1_map, idling_map_T4, PiEFm_Q0_map, idling_map_T3, PiEF_Q1_map, idling_map_T2, PiEF_Q0_map, idling_map_T1, Hadamard_Q0_dag_map])\n",
    "real_CMINm1_map = reduce(np.dot, [Hadamard_Q0_map, PiEFm_Q1_map, idling_map_T3, PiEFm_Q0_map, idling_map_T4, PiEF_Q1_map, idling_map_T1, PiEF_Q0_map, idling_map_T2, Hadamard_Q0_dag_map])\n",
    "\n",
    "ideal_CSUMm1_map = reduce(np.dot, [Hadamard_Q0_map, PiEFm_Q1_map, idling_nodecay_map_T4, PiEFm_Q0_map, idling_nodecay_map_T3, PiEF_Q1_map, idling_nodecay_map_T2, PiEF_Q0_map, idling_nodecay_map_T1, Hadamard_Q0_dag_map])\n",
    "ideal_CMINm1_map = reduce(np.dot, [Hadamard_Q0_map, PiEFm_Q1_map, idling_nodecay_map_T3, PiEFm_Q0_map, idling_nodecay_map_T4, PiEF_Q1_map, idling_nodecay_map_T1, PiEF_Q0_map, idling_nodecay_map_T2, Hadamard_Q0_dag_map])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrambling_map(CSUM_map, CMIN_map, scrambling_param = 1):\n",
    "    \"\"\" \n",
    "    When scrambling_param == 1, returns the scrambler.\n",
    "    When scrambling_param == 0, returns the identity\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    TwoQHad_unitary = np.kron(Hadamard_to_identity(scrambling_param), Hadamard_to_identity(scrambling_param))\n",
    "    TwoQHadDag_unitary = np.conj(TwoQHad_unitary).T\n",
    "    \n",
    "    \n",
    "    TwoQHad_map = unitary_op_to_map(TwoQHad_unitary)\n",
    "    TwoQHadDag_map = unitary_op_to_map(TwoQHadDag_unitary)\n",
    "    \n",
    "    return reduce(np.dot, [TwoQHadDag_map, CMIN_map, TwoQHad_map, CSUM_map])\n",
    "\n",
    "def Scrambling_star_map(CSUM_map, CMIN_map, scrambling_param = 1):\n",
    "    \"\"\" When scrambling_param == 1, returns the scrambler conjugate.\n",
    "    When scrambling_param == 0, returns the identity conjugate (which is just the identity)\"\"\"\n",
    "    \n",
    "    TwoQHadStar_unitary = np.kron(HadamardStar_to_identity(scrambling_param), HadamardStar_to_identity(scrambling_param))\n",
    "    TwoQHadDagStar_unitary = np.conj(TwoQHadStar_unitary).T\n",
    "    \n",
    "    TwoQHadStar_map = unitary_op_to_map(TwoQHadStar_unitary)\n",
    "    TwoQHadDagStar_map = unitary_op_to_map(TwoQHadDagStar_unitary)\n",
    "    \n",
    "    return reduce(np.dot, [TwoQHadDagStar_map, CMIN_map, TwoQHadStar_map, CSUM_map])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_scrambling_map = Scrambling_map(ideal_CSUMp1_map, ideal_CMINp1_map, 1)\n",
    "real_scrambling_map = Scrambling_map(real_CSUMp1_map, real_CMINp1_map, 1)\n",
    "\n",
    "ideal_scramblingstar_map = Scrambling_star_map(ideal_CSUMm1_map, ideal_CMINm1_map, 1)\n",
    "real_scramblingstar_map = Scrambling_star_map(real_CSUMm1_map, real_CMINm1_map, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hadamard_to_identity(alpha):\n",
    "    \"\"\" returns a single-qutrit unitary matrix which\n",
    "    smoothly interpolates between the Hadamard gate and the identity gate\n",
    "    When alpha is unity, it is the Hadamard\n",
    "    When alpha is zero, it is the identity\n",
    "    \"\"\"\n",
    "    \n",
    "    Hadamard_pulse_sequence = [['EFY-90'],\n",
    "    ['X90'],\n",
    "    ['Z{:.5f}'.format(-109.471*alpha)],\n",
    "    ['EFZ{:.5f}'.format(54.7355*alpha)],\n",
    "    ['X-90'],\n",
    "    ['Z{:.5f}'.format(180*alpha)],\n",
    "    ['EFZ{:.5f}'.format(-90*alpha)],\n",
    "    ['EFY90']]\n",
    "    \n",
    "    return resulting_unitary(Hadamard_pulse_sequence)\n",
    "\n",
    "def HadamardStar_to_identity(alpha):\n",
    "    \"\"\" returns a single-qutrit unitary matrix which\n",
    "    smoothly interpolates between the Hadamard gate and the identity gate\n",
    "    When alpha is unity, it is the Hadamard\n",
    "    When alpha is zero, it is the identity\n",
    "    \"\"\"\n",
    "    \n",
    "    Hadamard_pulse_sequence = [['EFY-90'],\n",
    "    ['X-90'],\n",
    "    ['Z{:.5f}'.format(109.471*alpha)],\n",
    "    ['EFZ{:.5f}'.format(-54.7355*alpha)],\n",
    "    ['X90'],\n",
    "    ['Z{:.5f}'.format(-180*alpha)],\n",
    "    ['EFZ{:.5f}'.format(90*alpha)],\n",
    "    ['EFY90']]\n",
    "    \n",
    "    return resulting_unitary(Hadamard_pulse_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qnl_ctrl.qnl_analysis import SimTools as ST\n",
    "from qnl_ctrl.qnl_analysis.SimTools import bit_to_trit, rot_x, rot_y, trit_z\n",
    "\n",
    "def resulting_unitary(pulse_sequence):\n",
    "    # starting from the initial state, calculates the unitary after the pulse_sequence is applied                                                                            \n",
    "    # here time flows from left to right, in that the first pulse in the pulse_string is the first pulse applied.\n",
    "    single_qutrit_unitary = np.eye(3)\n",
    "    for x in pulse_sequence:\n",
    "        pulse_string = x[0]\n",
    "        if pulse_string in list(qutrit_mapping.keys()):\n",
    "            single_qutrit_unitary = np.dot(qutrit_mapping[pulse_string], single_qutrit_unitary)\n",
    "        else:\n",
    "            if pulse_string[0] == 'Z':\n",
    "                phase = np.pi*float(pulse_string[1:])/180.\n",
    "                single_qutrit_unitary = np.dot(trit_z(phase,-1)[0], single_qutrit_unitary)\n",
    "\n",
    "            elif pulse_string[0:3] == 'EFZ':\n",
    "                phase = np.pi*float(pulse_string[3:])/180.\n",
    "                single_qutrit_unitary = np.dot(trit_z(phase,1)[0], single_qutrit_unitary)\n",
    "    return single_qutrit_unitary\n",
    "\n",
    "qutrit_mapping = {'I': np.eye(3, dtype='complex'),                                                                                                                               \n",
    "                  'GPrep': np.eye(3, dtype='complex'),\n",
    "                  'X90': bit_to_trit(rot_x(np.pi/2.)),\n",
    "                  'X-90': bit_to_trit(rot_x(-np.pi/2.)),\n",
    "                  'Y90': bit_to_trit(rot_y(np.pi/2.)),\n",
    "                  'Y-90': bit_to_trit(rot_y(-np.pi/2.)),\n",
    "                  'X270': bit_to_trit(rot_x(-np.pi/2.)),\n",
    "                  'Y270': bit_to_trit(rot_y(-np.pi/2.)),\n",
    "                  'X180': bit_to_trit(rot_x(np.pi)),\n",
    "                  'Y180': bit_to_trit(rot_y(np.pi)),\n",
    "                  'EFX90': bit_to_trit(rot_x(np.pi/2.), 1),\n",
    "                  'EFX-90': bit_to_trit(rot_x(-np.pi/2.), 1),\n",
    "                  'EFY90': bit_to_trit(rot_y(np.pi/2.), 1),\n",
    "                  'EFY-90': bit_to_trit(rot_y(-np.pi/2.), 1),\n",
    "                  'EFX270': bit_to_trit(rot_x(-np.pi/2.), 1),\n",
    "                  'EFY270': bit_to_trit(rot_y(-np.pi/2.), 1),\n",
    "                  'EFX180': bit_to_trit(rot_x(np.pi), 1),\n",
    "                  'EFY180': bit_to_trit(rot_y(np.pi), 1),\n",
    "                  'Delay': np.eye(3, dtype='complex'),\n",
    "                  'Hadamard': np.sqrt(1./3)*np.array([[1,1,1],\n",
    "                                        [1,np.exp(1j*2*np.pi/3),np.exp(-1j*2*np.pi/3)],\n",
    "                                        [1,np.exp(-1j*2*np.pi/3),np.exp(1j*2*np.pi/3)]]),\n",
    "                  'R': np.diag([1, np.exp(1j*2*np.pi/3),np.exp(1j*2*np.pi/3)])                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating our algorithm performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPR_state = np.array([1,0,0,0,1,0,0,0,1])/np.sqrt(3)\n",
    "\n",
    "psi0 = reduce(np.kron, [state_to_teleport, EPR_state, EPR_state])\n",
    "rho0 = ST.vec_to_dm(psi0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPR_projector = np.outer(EPR_state, np.conj(EPR_state))\n",
    "full_EPR_projector = reduce(np.kron, [np.eye(3), EPR_projector, np.eye(9)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to combine the maps to get the full five-qutrit quantum map.  Based on the equation below, \n",
    "\n",
    "\\begin{equation}\n",
    "\\hat { \\mathbf { A } } _ { i } \\hat { \\boldsymbol { \\rho } } \\hat { \\mathbf { A } } _ { i } ^ { \\dagger } \\rightarrow \\left( \\left( \\hat { \\mathbf { A } } _ { i } ^ { \\dagger } \\right) ^ { T } \\otimes \\hat { \\mathbf { A } } _ { i } \\right) \\vec { r }\n",
    "\\end{equation}\n",
    "\n",
    "we can infer that a general superoperator transforms as \n",
    "\\begin{equation}\n",
    "\\hat { \\mathbf { A } }  \\hat { \\boldsymbol { \\rho } } \\hat { \\mathbf { B } } \\rightarrow \\left( \\left( \\hat { \\mathbf { B } }  \\right) ^ { T } \\otimes \\hat { \\mathbf { A } }\\right) \\vec { r }\n",
    "\\end{equation}\n",
    "\n",
    "Unfortunately, as far as I can tell, there is no general way to combine two vectorized maps $\\mathcal{L}_1(\\rho_1)$ and $\\mathcal{L}_2(\\rho_2)$ to get vectorized form for the general map $\\mathcal{L}_{total}(\\rho_1 \\otimes \\rho_2) \\equiv \\mathcal{L}_1(\\rho_1) \\otimes \\mathcal{L}_2(\\rho_2)$.  But, it is pretty clear that if we have the Kraus representation for both the maps $\\mathcal{L}_1$ and $\\mathcal{L}_2$, then we can easily convert that to a vectorized superoperator.\n",
    "\n",
    "So, we have to now take a detour and figure out how to get the Kraus map from a vectorized superoperator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a Kraus map from a vectorized superoperator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer was given in [this paper](https://aip.scitation.org/doi/abs/10.1063/1.1518555) in 2003.  Basically, one converts from a superoperator $\\mathcal{S}$ to the so-called Choi matrix $\\mathcal{T}$ via the transformation \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{T} = \\sum_{i,j=0}^{N-1} \\left(\\mathbb{E}_{ij}\\otimes\\mathbb{I}\\right)\\mathcal{S}\\left( \\mathbb{I}\\otimes\\mathbb{E}_{ij}\\right),\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "where $\\mathbb{I}$ is the $N$ by $N$ identity matrix (where $N$ is the Hilbert space dimension, e.g. $N=9$ for a two-qutrit system), and $\\mathbb{E}_{ij}$ is the $N$ by $N$ matrix with a single element equal to unity (the $i,j$ element).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def ABsuperop_to_matrix(A, B):\n",
      "    \"\"\" given operators A and B, in terms of which the superoperator Sis defined as\n",
      "    S(rho) = A rho B, this method returns the matrix representation of S\"\"\"\n",
      "\n",
      "    return np.kron(B.T, A)\n",
      "\n",
      "def Kraus_ops_to_matrix(left_ops, right_ops):\n",
      "    \"\"\"given a list of left_ops and right_ops such that\n",
      "    S(rho) = sum_i leftops[i] rho rightops[i], this method returns the matrix representation of S\"\"\"\n",
      "    \n",
      "    return np.sum([ABsuperop_to_matrix(left_ops[i], right_ops[i]) for i in range(len(left_ops))],axis = 0)\n",
      "\n",
      "def E(i,j,N):\n",
      "    E_matrix = np.zeros((N,N))\n",
      "    E_matrix[i,j] = 1\n",
      "    return E_matrix\n",
      "\n",
      "def choi_matrix(superoperator_matrix):\n",
      "    \"\"\" Returns the Choi matrix corresopnding to the given superoperator-matrix. \"\"\"\n",
      "    \n",
      "    # make sure the superoperator_matrix is square\n",
      "    assert superoperator_matrix.shape[0] == superoperator_matrix.shape[1]\n",
      "    \n",
      "    Hilbert_space_dimension = int(np.floor(np.sqrt(superoperator_matrix.shape[0])))\n",
      "    assert Hilbert_space_dimension * Hilbert_space_dimension == superoperator_matrix.shape[0]\n",
      "    \n",
      "    choi_matrix_placeholder = np.zeros(superoperator_matrix.shape)\n",
      "    \n",
      "    for i in np.arange(Hilbert_space_dimension):\n",
      "        for j in np.arange(Hilbert_space_dimension):\n",
      "            EkronI = np.kron(E(i,j,Hilbert_space_dimension), np.eye(Hilbert_space_dimension))\n",
      "            IkronE = np.kron(np.eye(Hilbert_space_dimension), E(i,j,Hilbert_space_dimension))\n",
      "            MappedIkronE = np.dot(superoperator_matrix, IkronE)\n",
      "            choi_matrix_placeholder = choi_matrix_placeholder + np.dot(EkronI, MappedIkronE)\n",
      "    \n",
      "    return choi_matrix_placeholder\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(ST.ABsuperop_to_matrix))\n",
    "print(inspect.getsource(ST.Kraus_ops_to_matrix))\n",
    "print(inspect.getsource(ST.E))\n",
    "print(inspect.getsource(ST.choi_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the choi matrix $\\mathcal{T}$, we can use the SVD of T, i.e. the decomposition of $\\mathcal{T}$ into\n",
    "\\begin{equation}\n",
    "\\mathcal{T} \\equiv \\mathcal{V}\\mathcal{\\Omega}\\mathcal{W}^\\dagger = \\sum_{k=0}^{N^2-1} \\omega_k \\mathbf{v_k}\\mathbf{w_k}^\\dagger,\n",
    "\\end{equation}\n",
    "we can write that \n",
    "\\begin{equation}\n",
    "\\mathcal{S}\\mathrm{col}\\left( \\mathbf{X} \\right)  = \\mathrm{col} \\left( \\sum_{k=0}^{N^2-1} \\omega_k \\mathbf{V_k}\\mathbf{X}\\mathbf{W_k}^\\dagger \\right),\n",
    "\\end{equation}\n",
    "where $\\mathrm{col}(\\mathbf{V_k}) = \\mathbf{v}_k$ and $\\mathrm{col}(\\mathbf{W_k}) = \\mathbf{w}_k$.\n",
    "\n",
    "This is not exactly the Kraus form, but for our purposes we don't care that much, since we know how to vectorize things in the form above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def to_Kraus_ops(superoperator_matrix, svd_threshold = 1e-10):    \n",
      "    \"\"\"\n",
      "    Returns the Kraus operators corresponding to the superoperator_matrix\n",
      "    \n",
      "    Arguments:\n",
      "    superoperator_matrix: the matrix representation of the superoperator, in the vectorized basis\n",
      "    svd_threshold: the threshold value below which singular values are considered to be zero\n",
      "    \n",
      "    \"\"\"\n",
      "    Hilbert_space_dimension = int(np.floor(np.sqrt(superoperator_matrix.shape[0])))\n",
      "    assert Hilbert_space_dimension * Hilbert_space_dimension == superoperator_matrix.shape[0]\n",
      "\n",
      "    \n",
      "    # first convert the superoperator matrix into a Choi matrix\n",
      "    choi = choi_matrix(superoperator_matrix)\n",
      "    \n",
      "    u, s, v = np.linalg.svd(choi)\n",
      "    \n",
      "    #we don't really need u on their own, so we can just take the dot product of u and s\n",
      "    us = np.dot(u,np.diag(s))\n",
      "    \n",
      "    #to get the columns we should take the transpose of v\n",
      "    vT = v.T \n",
      "    \n",
      "    left_ops = []\n",
      "    right_ops = []\n",
      "    for i in range(superoperator_matrix.shape[0]):\n",
      "        if s[i] >= svd_threshold:\n",
      "            left_op = us[:,i].reshape(Hilbert_space_dimension, Hilbert_space_dimension).T\n",
      "            right_op = vT[:,i].reshape(Hilbert_space_dimension, Hilbert_space_dimension)\n",
      "            left_ops.append(left_op)\n",
      "            right_ops.append(right_op)\n",
      "        else:\n",
      "            break\n",
      "        \n",
      "    return left_ops, right_ops\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(ST.to_Kraus_ops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {'GS': np.array([1,0,0]), 'ES': np.array([0,1,0]), 'FS': np.array([0,0,1])}\n",
    "\n",
    "scrambling_param = 1\n",
    "\n",
    "teleportation_fidelities_ideal = {}\n",
    "teleportation_fidelities_real = {}\n",
    "\n",
    "EPR_state = np.array([1,0,0,0,1,0,0,0,1])/np.sqrt(3)\n",
    "\n",
    "\n",
    "ideal_scrambling_map = Scrambling_map(ideal_CSUMp1_map, ideal_CMINp1_map, scrambling_param)\n",
    "real_scrambling_map = Scrambling_map(real_CSUMp1_map, real_CMINp1_map, scrambling_param)\n",
    "\n",
    "ideal_scramblingstar_map = Scrambling_star_map(ideal_CSUMm1_map, ideal_CMINm1_map, scrambling_param)\n",
    "real_scramblingstar_map = Scrambling_star_map(real_CSUMm1_map, real_CMINm1_map, scrambling_param)\n",
    "\n",
    "###\n",
    "# calculate real evolution\n",
    "###\n",
    "l1real, r1real = ST.to_Kraus_ops(real_scrambling_map)\n",
    "l2real, r2real = ST.to_Kraus_ops(real_scramblingstar_map)\n",
    "\n",
    "ltotreal, rtotreal = ST.Krauslike_tensor(l1real, r1real, l2real, r2real)\n",
    "ltotreal, rtotreal = ST.Krauslike_tensor(ltotreal, rtotreal, [np.eye(3)], [np.eye(3)])\n",
    "\n",
    "###\n",
    "# calculate ideal evolution\n",
    "###\n",
    "\n",
    "l1ideal, r1ideal = ST.to_Kraus_ops(ideal_scrambling_map)\n",
    "l2ideal, r2ideal = ST.to_Kraus_ops(ideal_scramblingstar_map)\n",
    "\n",
    "ltotideal, rtotideal = ST.Krauslike_tensor(l1ideal, r1ideal, l2ideal, r2ideal)\n",
    "ltotideal, rtotideal = ST.Krauslike_tensor(ltotideal, rtotideal, [np.eye(3)], [np.eye(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.690707263744\n",
      "0.6662395752250001\n",
      "0.696181640625\n",
      "0.7109272172250001\n",
      "0.7552444263040001\n",
      "0.7174784556810001\n",
      "0.6904446648999999\n",
      "0.677635190596\n",
      "0.7319555359359999\n",
      "0.7092166225\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-504-070febcf8fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrho_app\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mltotreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mrho_app\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrho_app\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mltotreal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtotreal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mrho_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfull_EPR_projector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho_app\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_EPR_projector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_randomizations = 100\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for _ in range(n_randomizations):\n",
    "\n",
    "    input_state = np.random.randn(3) + 1j*np.random.randn(3)\n",
    "    input_state = input_state / np.linalg.norm(input_state)\n",
    "\n",
    "    input_dm = ST.vec_to_dm(input_state)\n",
    "\n",
    "    psi0 = reduce(np.kron, [input_state, EPR_state, EPR_state])\n",
    "    rho0 = ST.vec_to_dm(psi0)\n",
    "\n",
    "    rho_app = np.zeros(rho0.shape)\n",
    "    for i in range(len(ltotreal)):\n",
    "        rho_app = rho_app + reduce(np.dot, [ltotreal[i], rho0, rtotreal[i]])\n",
    "\n",
    "    rho_proj = reduce(np.dot, [full_EPR_projector, rho_app, full_EPR_projector])\n",
    "    rho_proj = rho_proj / np.trace(rho_proj)\n",
    "\n",
    "    final_state = ST.partial_trace(rho_proj, k = 0, dim = [[81,81],[3,3]])\n",
    "    final_state = final_state / np.trace(final_state)\n",
    "\n",
    "    fid = ST.fidelity(final_state, input_dm)\n",
    "    fidelities.append(fid)\n",
    "    print(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
